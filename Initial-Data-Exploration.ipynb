import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import glob

print("Healthcare Data Analysis Project")
print("=" * 40)

# Load the main nursing file first
main_file = "PBJ_Daily_Nurse_Staffing_Q2_2024.csv"

print("\nStep 1: Load Files")
print("-" * 20)

# Try to read the main file
try:
    nursing_df = pd.read_csv(main_file)
except:
    # If it fails, try with different encoding
    nursing_df = pd.read_csv(main_file, encoding='latin-1')

print(f"Main file loaded: {main_file}")
print(f"Size: {nursing_df.shape}")

# Get all other CSV files
other_files = glob.glob("*.csv")
other_files.remove(main_file)  # Remove main file from list

# Load all the other files
all_data = {main_file: nursing_df}

for file in other_files:
    try:
        df = pd.read_csv(file)
    except:
        try:
            df = pd.read_csv(file, encoding='latin-1')
        except:
            print(f"Couldn't load {file}")
            continue
    
    all_data[file] = df
    print(f"Loaded {file}: {len(df)} rows")

print(f"\nTotal files loaded: {len(all_data)}")

# Look at the main dataset structure
print("\nStep 2: Check Main Dataset")
print("-" * 30)

print(f"Main dataset shape: {nursing_df.shape}")
print(f"Columns: {len(nursing_df.columns)}")

# Check if we have the columns we expect
expected_cols = ['PROVNUM', 'PROVNAME', 'STATE', 'MDScensus', 'Hrs_RN', 'Hrs_LPN', 'Hrs_CNA']
found_cols = []
for col in expected_cols:
    if col in nursing_df.columns:
        found_cols.append(col)

print(f"Expected columns found: {len(found_cols)}/{len(expected_cols)}")

# Basic stats
if 'PROVNUM' in nursing_df.columns:
    print(f"Number of facilities: {nursing_df['PROVNUM'].nunique()}")
if 'STATE' in nursing_df.columns:
    print(f"Number of states: {nursing_df['STATE'].nunique()}")

# Look at all columns in detail
print("\nStep 3: Column Details")
print("-" * 25)

print("Column breakdown:")
for i, col in enumerate(nursing_df.columns):
    missing = nursing_df[col].isnull().sum()
    missing_pct = (missing / len(nursing_df)) * 100
    unique_vals = nursing_df[col].nunique()
    
    print(f"{i+1:2d}. {col:25s} - Missing: {missing_pct:5.1f}% - Unique: {unique_vals:6d}")

# Group columns by type
print("\nColumn groups:")

# Facility info
facility_columns = []
for col in nursing_df.columns:
    if any(word in col.upper() for word in ['PROV', 'NAME', 'CITY', 'STATE', 'COUNTY']):
        facility_columns.append(col)
if facility_columns:
    print(f"Facility info: {facility_columns}")

# Time columns  
time_columns = []
for col in nursing_df.columns:
    if any(word in col.upper() for word in ['DATE', 'QTR']):
        time_columns.append(col)
if time_columns:
    print(f"Time info: {time_columns}")

# Nursing hours columns
rn_columns = []
lpn_columns = []
cna_columns = []

for col in nursing_df.columns:
    if 'RN' in col.upper() and 'HRS' in col.upper():
        rn_columns.append(col)
    elif 'LPN' in col.upper():
        lpn_columns.append(col)
    elif 'CNA' in col.upper():
        cna_columns.append(col)

if rn_columns:
    print(f"RN hours: {len(rn_columns)} columns")
if lpn_columns:
    print(f"LPN hours: {len(lpn_columns)} columns") 
if cna_columns:
    print(f"CNA hours: {len(cna_columns)} columns")

# Employee vs contract
emp_cols = [col for col in nursing_df.columns if col.endswith('_emp')]
ctr_cols = [col for col in nursing_df.columns if col.endswith('_ctr')]
print(f"Employee columns: {len(emp_cols)}")
print(f"Contract columns: {len(ctr_cols)}")

# Check relationships between files
print("\nStep 4: File Relationships")
print("-" * 30)

# Find common columns
all_columns = {}
for filename, df in all_data.items():
    for col in df.columns:
        if col not in all_columns:
            all_columns[col] = []
        all_columns[col].append(filename)

# Show columns that appear in multiple files
common_cols = {}
for col, files in all_columns.items():
    if len(files) > 1:
        common_cols[col] = files

print("Columns in multiple files:")
for col, files in common_cols.items():
    if main_file in files:
        other_files_with_col = [f for f in files if f != main_file]
        if other_files_with_col:
            print(f"  {col}: main + {len(other_files_with_col)} others")

# Check potential join keys
join_keys = ['PROVNUM', 'PROVNAME', 'STATE']

for key in join_keys:
    if key in nursing_df.columns:
        main_values = set(nursing_df[key].dropna())
        print(f"\n{key} as join key:")
        print(f"  Main file has {len(main_values)} unique values")
        
        for filename, df in all_data.items():
            if filename != main_file and key in df.columns:
                other_values = set(df[key].dropna())
                overlap = len(main_values.intersection(other_values))
                overlap_pct = (overlap / len(main_values)) * 100 if main_values else 0
                
                print(f"  {filename[:30]}...")
                print(f"    Has {len(other_values)} values, {overlap} match ({overlap_pct:.1f}%)")

# Data quality check
print("\nStep 5: Data Quality")
print("-" * 25)

# Missing data
missing_by_col = nursing_df.isnull().sum()
cols_with_missing = missing_by_col[missing_by_col > 0]

print(f"Columns with missing data: {len(cols_with_missing)}")
if len(cols_with_missing) > 0:
    print("Worst 5 columns:")
    worst_missing = cols_with_missing.sort_values(ascending=False).head(5)
    for col, missing_count in worst_missing.items():
        pct = (missing_count / len(nursing_df)) * 100
        print(f"  {col}: {missing_count} missing ({pct:.1f}%)")

# Duplicates
duplicates = nursing_df.duplicated().sum()
print(f"Duplicate rows: {duplicates}")

# Simple charts
print("\nStep 6: Basic Charts")
print("-" * 20)

if 'STATE' in nursing_df.columns:
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # States chart
    state_counts = nursing_df['STATE'].value_counts().head(10)
    state_counts.plot(kind='bar', ax=ax1, color='lightblue')
    ax1.set_title('Records by State (Top 10)')
    ax1.set_xlabel('State')
    ax1.tick_params(axis='x', rotation=45)
    
    # Missing data chart
    if len(cols_with_missing) > 0:
        missing_pcts = (cols_with_missing / len(nursing_df) * 100).head(8)
        missing_pcts.plot(kind='barh', ax=ax2, color='orange')
        ax2.set_title('Missing Data by Column')
        ax2.set_xlabel('Percent Missing')
    else:
        ax2.text(0.5, 0.5, 'No Missing Data', ha='center', va='center')
        ax2.set_title('Missing Data Check')
    
    plt.tight_layout()
    plt.show()

# Summary table
print("\nStep 7: File Summary")
print("-" * 20)

print(f"{'File':<35} {'Rows':>8} {'Cols':>5} {'Missing%':>8}")
print("-" * 60)

for filename, df in all_data.items():
    total_cells = len(df) * len(df.columns)
    missing_cells = df.isnull().sum().sum()
    missing_pct = (missing_cells / total_cells) * 100
    
    short_name = filename[:32] + "..." if len(filename) > 35 else filename
    print(f"{short_name:<35} {len(df):>8} {len(df.columns):>5} {missing_pct:>7.1f}")

# Look at some other files
print("\nStep 8: Other Files")
print("-" * 20)

keywords = ['facility', 'performance', 'quality']
for filename, df in all_data.items():
    if filename != main_file:
        for keyword in keywords:
            if keyword in filename.lower():
                print(f"\n{filename}:")
                print(f"  Columns: {list(df.columns)}")
                break

print("\n" + "="*40)
print("ANALYSIS DONE")
